# Multi-stage vLLM Dockerfile for CPU-only UBI 10
# Stage 1: Build environment with all development tools
# Stage 2: Build vLLM wheel
# Stage 3: Minimal runtime environment with vLLM installed
#
# Build arguments:
#   PYTHON_VERSION=3.13|3.12 (default)|3.11|3.10
#   VLLM_VERSION=v0.10.0 (default)|latest|main|<tag>|<branch>
#   VLLM_CPU_DISABLE_AVX512=false (default)|true
#   VLLM_CPU_AVX512BF16=false (default)|true
#   VLLM_CPU_AVX512VNNI=false (default)|true

###############################
# Stage 1: Base Image
###############################
FROM registry.access.redhat.com/ubi10 AS base

ARG PYTHON_VERSION=3.12
ARG PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cpu"
ARG VLLM_VERSION="v0.10.0"
ARG NUMACTL_VERSION=2.0.19

USER 0

WORKDIR /workspace

RUN --mount=type=cache,target=/var/cache/dnf,sharing=locked \
    dnf -y update && \
    INSTALL_PKGS="python3 python3-devel git wget gcc gcc-c++ cmake make" && \
    dnf install -y --setopt=tsflags=nodocs $INSTALL_PKGS && \
    rpm -V $INSTALL_PKGS && \
    dnf clean all

# Install uv (fast Python package installer)
RUN curl -LsSf https://astral.sh/uv/install.sh | sh && \
    export PATH="/root/.local/bin:/root/.cargo/bin:$PATH"

# Set build environment variables
ENV CFLAGS="-O3 -mavx2 -mf16c -fopenmp"
ENV CXXFLAGS="${CFLAGS}"
ENV PATH="/root/.local/bin:/root/.cargo/bin:$PATH"
ENV VIRTUAL_ENV="/opt/venv"
ENV PIP_EXTRA_INDEX_URL=${PIP_EXTRA_INDEX_URL}
ENV UV_EXTRA_INDEX_URL=${PIP_EXTRA_INDEX_URL}
ENV UV_PYTHON_INSTALL_DIR="/opt/uv/python"
ENV UV_INDEX_STRATEGY="unsafe-best-match"
ENV UV_LINK_MODE="copy"
ENV UV_HTTP_TIMEOUT=500

# Create virtual environment
RUN uv venv --python ${PYTHON_VERSION} --seed ${VIRTUAL_ENV}
ENV PATH="$VIRTUAL_ENV/bin:$PATH"

# Build numactl from source to get headers and libraries
RUN --mount=type=cache,target=/tmp/numactl-build \
    cd /tmp/numactl-build && \
    wget -O numactl-${NUMACTL_VERSION}.tar.gz \
    "https://github.com/numactl/numactl/releases/download/v${NUMACTL_VERSION}/numactl-${NUMACTL_VERSION}.tar.gz" && \
    tar xf numactl-${NUMACTL_VERSION}.tar.gz && \
    cd numactl-${NUMACTL_VERSION} && \
    ./configure --prefix=/usr/local && \
    make -j$(nproc) && \
    make install && \
    ldconfig

# Clone vLLM source code at specific version
# RUN git clone --depth 1 --branch $VLLM_VERSION https://github.com/vllm-project/vllm.git && \
#     cd vllm && \
#     git log --oneline -1

# Install vLLM build and runtime dependencies
RUN --mount=type=cache,target=/root/.cache/uv \
    --mount=type=bind,src=requirements/common.txt,target=requirements/common.txt \
    --mount=type=bind,src=requirements/cpu.txt,target=requirements/cpu.txt \
    uv pip install --upgrade pip && \
    uv pip install -r requirements/cpu.txt

###############################
# Stage 2: Build Environment
###############################
FROM base AS builder

ARG GIT_REPO_CHECK=0
# Support for building with non-AVX512 vLLM: docker build --build-arg VLLM_CPU_DISABLE_AVX512="true" ...
ARG VLLM_CPU_DISABLE_AVX512=false
ARG VLLM_CPU_AVX512BF16=true
ARG VLLM_CPU_AVX512VNNI=true

ENV VLLM_CPU_DISABLE_AVX512=${VLLM_CPU_DISABLE_AVX512}
ENV VLLM_CPU_AVX512BF16=${VLLM_CPU_AVX512BF16}
ENV VLLM_CPU_AVX512VNNI=${VLLM_CPU_AVX512VNNI}

WORKDIR /workspace/vllm
COPY . .

# Optional repository check
RUN if [ "$GIT_REPO_CHECK" != 0 ]; then bash tools/check_repo.sh ; fi

# install build requirements
RUN --mount=type=cache,target=/root/.cache/uv \
    uv pip install -r requirements/cpu-build.txt

# Build vLLM wheel
RUN --mount=type=cache,target=/root/.cache/uv \
    --mount=type=cache,target=/workspace/vllm/.deps,sharing=locked \
    VLLM_TARGET_DEVICE=cpu python3 setup.py bdist_wheel

###############################
# Stage 3: Runtime Environment
###############################
FROM registry.access.redhat.com/ubi10 AS runtime

# Pass Python version to runtime stage
ARG PYTHON_VERSION=3.12

# Runtime environment variables
# https://docs.vllm.ai/en/stable/getting_started/installation/cpu.html#related-runtime-environment-variables
ARG VLLM_CPU_KVCACHE_SPACE=0
ARG VLLM_CPU_OMP_THREADS_BIND=auto
ARG VLLM_CPU_NUM_OF_RESERVED_CPU=None
ARG CPU_VISIBLE_MEMORY_NODES=
ARG VLLM_CPU_MOE_PREPACK=1
ARG VLLM_CPU_SGL_KERNEL=0

ENV VLLM_CPU_KVCACHE_SPACE=${VLLM_CPU_KVCACHE_SPACE}
ENV VLLM_CPU_OMP_THREADS_BIND=${VLLM_CPU_OMP_THREADS_BIND}
ENV VLLM_CPU_NUM_OF_RESERVED_CPU=${VLLM_CPU_NUM_OF_RESERVED_CPU}
ENV CPU_VISIBLE_MEMORY_NODES=${CPU_VISIBLE_MEMORY_NODES}
ENV VLLM_CPU_MOE_PREPACK=${VLLM_CPU_MOE_PREPACK}
ENV VLLM_CPU_SGL_KERNEL=${VLLM_CPU_SGL_KERNEL}

USER 0
WORKDIR /workspace

# Install Python 3.12 specifically and minimal runtime dependencies
RUN --mount=type=cache,target=/var/cache/dnf,sharing=locked \
    dnf -y update && \
    dnf install -y --setopt=tsflags=nodocs python3.12 python3.12-pip && \
    dnf clean all && \
    # Create symlinks to make Python 3.12 the default python3
    ln -sf /usr/bin/python3.12 /usr/bin/python3 && \
    ln -sf /usr/bin/pip3.12 /usr/bin/pip3

# Copy artifacts from previous stages
COPY --from=base /usr/local/lib/libnuma* /usr/local/lib/
COPY --from=base /usr/local/bin/numa* /usr/local/bin/
COPY --from=builder /workspace/vllm /workspace/vllm

# Set up environment
ENV LD_LIBRARY_PATH="/usr/local/lib:$LD_LIBRARY_PATH"

# Install vLLM wheel using Python 3.12 (no UV needed in runtime)
ARG PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cpu"
RUN --mount=type=bind,from=builder,src=/workspace/vllm/dist,target=/tmp \
    echo "Python version:" && python3 --version && \
    python3 -m pip install --upgrade pip && \
    python3 -m pip install /tmp/*.whl && \
    ldconfig

# Set system-wide core dump limits
RUN echo "* soft core 0" >> /etc/security/limits.conf && \
    echo "* hard core 0" >> /etc/security/limits.conf

# Create user
RUN useradd -m -u 1001 -g root -s /bin/bash vllm

# Verify installation with Python 3.12
RUN python3 -c "import sys; print(f'Python version: {sys.version}')" && \
    python3 -c "import vllm; print(f'vLLM {vllm.__version__} ready for runtime')" && \
    numactl --version

USER 1001
WORKDIR /workspace/vllm

# Start vLLM server using Python 3.12
ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]
